{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization\n",
    "\n",
    "[This pdf](https://github.com/mtomassoli/information-theory-tutorial) helped me a lot, but mainly with other stuff than EM. I also found a great blog [here](https://nipunbatra.github.io/blog/2014/em.html). Also, [this](https://www.cs.utah.edu/~piyush/teaching/EM_algorithm.pdf) explanation is more mathy.\n",
    "\n",
    "Iterative method, two steps:\n",
    "* Expectation - Creates a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters. What are calculated in the first step are the fixed, data-dependent parameters of the function Q.\n",
    "* Maximization - Computes parameters maximizing the expected log-likelihood found on the E step. Once the parameters of Q are known, it is fully determined and is maximized in the second (M) step of an EM algorithm.\n",
    "\n",
    "Other methods exist to find maximum likelihood estimates, such as gradient descent, conjugate gradient, or variants of the Gaussâ€“Newton algorithm. Unlike EM, such methods typically require the evaluation of first and/or second derivatives of the likelihood function.\n",
    "\n",
    "1. First, initialize the parameters $\\boldsymbol {\\theta }$ to some random values.\n",
    "2. Compute the probability of each possible value of $\\mathbf {Z}$, given $\\boldsymbol {\\theta }$.\n",
    "3. Then, use the just-computed values of $\\mathbf {Z}$  to compute a better estimate for the parameters ${\\boldsymbol {\\theta }}$.\n",
    "4. Iterate steps 2 and 3 until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "We have 0 or 1 sample data drawn from two Bernoulli distributions. Variable with Bernoulli distribution takes 1 with probability p and 0 with probability 1 - p, where p is a distribution parameter. We don't know from which distribution a sample comes from.\n",
    "\n",
    "Maximum likelihood estimate of p is a sample mean $\\frac{1}{n} \\sum_i^n x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "import itertools as it\n",
    "import json\n",
    "import math\n",
    "import operator as op\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interact_manual, widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import misc, stats\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.array([[1,0,0,0,1,1,0,1,0,1], # the assumption is that each row comes from a single distribution\n",
    "                         [1,1,1,1,0,1,1,1,1,1], # makes sense, without it the solution would probably be that \n",
    "                         [1,0,1,1,1,1,1,0,1,1], # all ones comes from a dist with p=1 and all zeros from p=0\n",
    "                         [1,0,1,0,0,0,1,1,0,0], \n",
    "                         [0,1,1,1,0,1,1,1,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 0.8\n"
     ]
    }
   ],
   "source": [
    "# if we know from which distributions the observations come from, we can simply calculate \n",
    "# the params from ml estimator\n",
    "\n",
    "distribution_ids = np.array([0, 1, 1, 0, 1]) # hidden params\n",
    "\n",
    "p_0 = observations[distribution_ids == 0].mean()\n",
    "p_1 = observations[distribution_ids == 1].mean()\n",
    "\n",
    "print(p_0, p_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44914893  0.80498552  0.73346716  0.35215613  0.64721512]\n",
      " [ 0.55085107  0.19501448  0.26653284  0.64784387  0.35278488]]\n",
      "[[ 0.71301224]\n",
      " [ 0.58133931]]\n"
     ]
    }
   ],
   "source": [
    "# start from some random numbers, you might get different results depending on choice though\n",
    "# visible: model_n, visible_size; hidden: model_n, hidden_size; \n",
    "# observations: observation_n (= hidden_size), observation_size \n",
    "\n",
    "visible_params = np.array([[0.6], [0.5]])\n",
    "\n",
    "def estimate_hidden_params(observations, visible_params):\n",
    "    hits = observations.sum(axis=1)\n",
    "    _, observation_size = observations.shape\n",
    "    \n",
    "    model_probs = stats.binom.pmf(hits, observation_size, visible_params)\n",
    "        \n",
    "    total_probs = model_probs.sum(axis=0)\n",
    "    return model_probs / total_probs\n",
    "    \n",
    "hidden_params = estimate_hidden_params(observations, visible_params)\n",
    "print(hidden_params)\n",
    "\n",
    "def maximize_visible_params(observations, hidden_params):\n",
    "    per_observation_estimates = observations.mean(axis=1)\n",
    "    # (model_n, hidden_size) x (observation_n = hidden_size, visible_size) = (model_n, visible_size)\n",
    "    visible_estimates = hidden_params @ per_observation_estimates / hidden_params.sum(axis=1)\n",
    "    return visible_estimates[:, np.newaxis]\n",
    "      \n",
    "visible_params = maximize_visible_params(observations, hidden_params)\n",
    "print(visible_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.79678907]\n",
      " [ 0.51958312]]\n",
      "[[ 0.10300871  0.95201348  0.84549373  0.03070315  0.6014986 ]\n",
      " [ 0.89699129  0.04798652  0.15450627  0.96929685  0.3985014 ]]\n"
     ]
    }
   ],
   "source": [
    "def expectation_maximization(observations, initial_visible, iterations):\n",
    "    visible_params = initial_visible\n",
    "    for i in range(iterations):\n",
    "        hidden_params = estimate_hidden_params(observations, visible_params)\n",
    "        visible_params = maximize_visible_params(observations, hidden_params)\n",
    "    return visible_params, hidden_params\n",
    "\n",
    "visible_params, hidden_params = expectation_maximization(\n",
    "    observations, np.array([[0.6], [0.5]]), 1000\n",
    ")\n",
    "print(visible_params)\n",
    "print(hidden_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real values were \n",
    "\n",
    "* visible params [0.45 0.8]\n",
    "* hidden params [0, 1, 1, 0, 1]\n",
    "\n",
    "The algorithms swapped first distribution with second, but it's perfectly fine, they're just identified in different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.83938928],\n",
       "        [ 0.06061072]]),\n",
       " array([[ 0.93265475,  0.14600975,  0.93265475,  0.14600975,  0.14600975,\n",
       "          0.93265475,  0.14600975,  0.93265475,  0.93265475,  0.14600975,\n",
       "          0.14600975,  0.14600975,  0.93265475,  0.14600975,  0.93265475,\n",
       "          0.93265475,  0.14600975,  0.93265475,  0.14600975,  0.14600975],\n",
       "        [ 0.06734525,  0.85399025,  0.06734525,  0.85399025,  0.85399025,\n",
       "          0.06734525,  0.85399025,  0.06734525,  0.06734525,  0.85399025,\n",
       "          0.85399025,  0.85399025,  0.06734525,  0.85399025,  0.06734525,\n",
       "          0.06734525,  0.85399025,  0.06734525,  0.85399025,  0.85399025]]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_maximization(\n",
    "    np.array([[1], [0], [1], [0], [0], \n",
    "              [1], [0], [1], [1], [0], \n",
    "              [0], [0], [1], [0], [1], \n",
    "              [1], [0], [1], [0], [0]]), \n",
    "    np.array([[0.90], [0.10]]), \n",
    "    1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.45],\n",
       "        [ 0.45]]), array([[ 0.5],\n",
       "        [ 0.5]]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_maximization(\n",
    "    np.array([[1, 0, 1, 0, 0, \n",
    "               1, 0, 1, 1, 0, \n",
    "               0, 0, 1, 0, 1, \n",
    "               1, 0, 1, 0, 0]]), \n",
    "    np.array([[0.75], [0.25]]), \n",
    "    1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.45]), array([[ 1.]]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_maximization(\n",
    "    np.array([[1, 0, 1, 0, 0, \n",
    "               1, 0, 1, 1, 0, \n",
    "               0, 0, 1, 0, 1, \n",
    "               1, 0, 1, 0, 0]]), \n",
    "    np.array([[0.75]]), \n",
    "    1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.50237364,  0.50217056,  0.49782944,  0.49762636]),\n",
       " array([[ 0.25356136,  0.25118595,  0.2488122 ,  0.24644049],\n",
       "        [ 0.2532549 ,  0.25108626,  0.24891559,  0.24674325],\n",
       "        [ 0.24674325,  0.24891559,  0.25108626,  0.2532549 ],\n",
       "        [ 0.24644049,  0.2488122 ,  0.25118595,  0.25356136]]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_maximization(\n",
    "    np.array([[1, 0, 1, 1, 1], \n",
    "              [1, 0, 1, 1, 0], \n",
    "              [0, 0, 1, 0, 1], \n",
    "              [1, 0, 0, 0, 0]]), \n",
    "    np.array([[0.8], [0.6], [0.4], [0.2]]), \n",
    "    10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixtures\n",
    "\n",
    "I will now use the same algorithm, but for continuous-valued observations from normal distributions.\n",
    "\n",
    "https://www.ics.uci.edu/~smyth/courses/cs274/notes/EMnotes.pdf (but it's really similar to the solution above)\n",
    "\n",
    "Important observation: When setting initial parameters, you need to use high std deviations, so that the algorithms gets a non-zero probability for all observations. If you set the stdev to something very low, the probability of some observations may be 0 for all models. In theory they should be never exactly 0, but they will be too low to correctly represent in float64 datatype. When you get all 0s further calculations will result in a lot of NaNs and algorithm will fail to produce a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_hidden_params_gm(observations, visible_params):\n",
    "    model_n = visible_params.shape[0]\n",
    "    observation_n = observations.shape[0]\n",
    "    model_probs = np.zeros((model_n, observation_n), dtype=np.float64)\n",
    "    \n",
    "    for i, visible_params_row in enumerate(visible_params):\n",
    "        single_model_probs = stats.norm.pdf(observations, *visible_params_row)\n",
    "        single_model_per_row_probs = np.product(single_model_probs, axis=1)\n",
    "        model_probs[i, :] = single_model_per_row_probs\n",
    "    \n",
    "    total_probs = model_probs.sum(axis=0)\n",
    "    return model_probs / total_probs\n",
    "\n",
    "def maximize_visible_params_gm(observations, hidden_params):\n",
    "    mean_estimates = observations.mean(axis=1)\n",
    "    std_estimates = observations.std(axis=1, ddof=1)\n",
    "    per_observation_estimates = np.vstack((mean_estimates, std_estimates)).T\n",
    "    # (model_n, hidden_size) x (observation_n = hidden_size, visible_size) = (model_n, visible_size)\n",
    "    visible_estimates = hidden_params @ per_observation_estimates / hidden_params.sum(axis=1)\n",
    "    return visible_estimates\n",
    "\n",
    "def expectation_maximization_gm(observations, initial_visible, iterations):\n",
    "    visible_params = initial_visible\n",
    "    for i in range(iterations):\n",
    "        hidden_params = estimate_hidden_params_gm(observations, visible_params)\n",
    "        visible_params = maximize_visible_params_gm(observations, hidden_params)\n",
    "    return visible_params, hidden_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.73138631  38.68844962  31.08984531  49.72170174  15.10917116\n",
      "   27.09386767  -4.64964849  31.67360694  25.95483314  29.25336147]\n",
      " [-10.6357767   -8.97528692  -9.36660848 -10.05024844  -9.72180614\n",
      "  -10.53131243  -8.82668543 -11.68404029  -9.16825313  -9.61380038]\n",
      " [-10.09427618 -10.13917496  -9.74683926 -10.63816671  -9.72704352\n",
      "  -10.23403944  -9.22729174 -10.31016058  -9.45440579 -10.8207077 ]\n",
      " [ 18.45307559  21.00533734  37.44963202  28.90126467  44.80198507\n",
      "   47.77182779  29.44311313  40.87891534  46.57039318  16.96715578]\n",
      " [-10.42086735 -10.54406874  -9.29479122  -9.25389654 -10.25204651\n",
      "  -10.58037044  -9.71916536  -9.78374837 -10.13441805 -10.44336988]]\n"
     ]
    }
   ],
   "source": [
    "def generate_norm(params, size, indexes):\n",
    "    return np.array([stats.norm.rvs(*params[i], size) for i in indexes])\n",
    "\n",
    "print(generate_norm(np.array([[-10, 0.5], [30, 15]]), 10, [1, 0, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.97321562,  0.99401806],\n",
       "        [-1.76863526,  1.96558517]]),\n",
       " array([[  1.00000000e+000,   3.16325599e-180,   4.45726359e-221,\n",
       "           1.00000000e+000,   1.58790268e-216],\n",
       "        [  6.10627986e-063,   1.00000000e+000,   1.00000000e+000,\n",
       "           1.11048813e-058,   1.00000000e+000]]))"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_maximization_gm(\n",
    "    generate_norm(np.array([[-1, 2], [3, 1.5]]), 50, [1, 0, 0, 1, 0]),\n",
    "    np.array([[1.0, 1.0], [-1.0, 1.0]]),\n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 3.45806671,  5.17141297],\n",
       "        [ 0.9473763 ,  0.98778509]]),\n",
       " array([[  1.00000000e+00,   1.81537388e-52,   6.69137843e-55,\n",
       "           1.00000000e+00,   9.77532111e-59,   1.55593867e-60,\n",
       "           1.00000000e+00,   1.00000000e+00,   1.15272900e-56,\n",
       "           1.00000000e+00],\n",
       "        [  0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "           0.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "           0.00000000e+00]]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_maximization_gm(\n",
    "    generate_norm(np.array([[1, 1], [3, 5]]), 100, [1, 0, 0, 1, 0, 0, 1, 1, 0, 1]),\n",
    "    np.array([[1.0, 10.0], [-1.0, 10.0]]),\n",
    "    100\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
