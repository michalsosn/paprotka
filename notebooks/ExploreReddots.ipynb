{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RedDots Dataset release r2015q4_v1\n",
    "\n",
    "RedDots dataset can be downloaded for free [here](https://sites.google.com/site/thereddotsproject/reddots-challenge).\n",
    "\n",
    "It's target was to get 52 sessions per speaker, 24 sentences for each session: 10 common for all speakers, 10 unique to each speaker, 2 sentences of free choice, 2 free text.\n",
    "\n",
    "It has 62 speakers including 49 male speakers and 13 female speakers from 21 countries. The total number of sessions for the current release is 572 (473 male and 99 female sessions). There are 15306 recordings.\n",
    "\n",
    "## File / path format (mainly interesting for reading the data)\n",
    "\n",
    "### /pcm folder contains .pcm files with recordings\n",
    "\n",
    "Recordings have format\n",
    "`pcm/{speaker}/{recording}.pcm`\n",
    "where\n",
    "`{speaker} = {gender}{speaker_id}`\n",
    "`{recording} = {speaker}/{timestamp}_{speaker}_{sentence}`\n",
    "\n",
    "They simply contain uncompressed sequences of samples. The values are signed int16 and the frequency of samples is 16kHz. \n",
    "\n",
    "### /ndx contains definitions of test sets\n",
    "\n",
    "There are 4 proposed trials based on the gathered recordings. They use common, unique, free-choice and text-prompted sentence recordings respectively.\n",
    "\n",
    "#### .trn - train set, enrollments\n",
    "`{speaker}_{sentence} {recording},{recording},{recording}`\n",
    "(the fourth test set has 4 recordings per enrollment)\n",
    "\n",
    "eg. `m0001_31 m0001/20150130084154554_m0001_31,m0001/20150130084155412_m0001_31,m0001/20150130084156114_m0001_31`\n",
    "\n",
    "#### .ndx - test set, trials\n",
    "\n",
    "`{speaker}_{sentence},{recording},{target correct},{target wrong},{imposter correct},{imposter wrong}`\n",
    "\n",
    "eg. `m0001_31,m0001/20150129213253016_m0001_36,N,Y,N,N`\n",
    "\n",
    "The N, Y sequence means in order:\n",
    "\n",
    "* target - same person\n",
    "* imposter - different person\n",
    "* correct - same sentence\n",
    "* wrong - different sentence\n",
    "\n",
    "There is some redundancy in those values. Only one of them can be set to 'Y' for a sample. Moreover, `target = Y` means that the speaker identifier on the left (in the `{speaker}_{sentence}` part) is same as the on right (in the `{recording}` part), while `imposter = Y` means they are different. Similarly, when `correct = Y` the sentence number on the left is equal to the number on the right and when `wrong = Y` they are different.\n",
    "\n",
    "#### Parts\n",
    "\n",
    "* Part 01: Common Pass-phrases Text-Dependent. All speakers say sentences with ids 31-40, which come from TIMIT. Train set contains of recordings where a person (with exception of several people excluded to be 'imposters') says one of the ten sentences. All combinations are covered three times, with three sessions. Test set uses a different recordings.\n",
    "* Part 02: Unique Pass-phrases Text-Dependent. Unique to each speaker, same across sessions, assigned to speakers by the dataset creator. The difference is that since each speaker has a different set of sentences, there is no case of an impostor saying a correct sentence.\n",
    "* Part 03: Free-choice Pass-phrases Text-Dependent. Unique to each speaker, same across session, chosen by the recorded people. Like in part 02 there are no cases ofan impostor saying a correct sentence. The difference is that the sentences are chosen by the enrolling people, so they could be too short or not cover many phonemes.\n",
    "* Part 04: Text-Prompted. Unique across sessions, excerpts from Wikipedia. It consists of two subparts: \n",
    " * tp - text prompted/independent, there are six text-prompted recordings per person in the training set. Recordings with same content are not present in the test set.\n",
    " * td - text dependent. Train set consist of recordings from parts 1-3. Test set has recordings from parts 1-3 and also text-prompted recordings.\n",
    " \n",
    "Sessions 2, 4, 6 are used for enrollment, except for text-prompted case where sessions 1, 2, 3, 4, 6 are used.\n",
    "\n",
    "Test sets in .ndx are very large, because they contain all possible pairs of test `{speaker}_{sentence}` and test recordings. \n",
    "\n",
    "Test sets contain both previously registered people and impostors that are not enrolled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "import itertools as it\n",
    "import math\n",
    "import operator as op\n",
    "import os\n",
    "import re\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interact_manual, widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import misc, signal\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('m', '0001', '20150129213253016', '36')\n",
      "('m', '0001', '31')\n",
      "2015-01-29 21:32:53.016000\n"
     ]
    }
   ],
   "source": [
    "def read_files(*paths):\n",
    "    for path in paths:\n",
    "        with open(path) as opened:\n",
    "            yield from opened.readlines()\n",
    "\n",
    "\n",
    "recording_regex = re.compile(r'([mf])(\\d+)/(\\d+)_[mf]\\d+_(\\d+)')\n",
    "def parse_recording(value):\n",
    "    match = recording_regex.match(value)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "\n",
    "print(parse_recording('m0001/20150129213253016_m0001_36'))\n",
    "\n",
    "\n",
    "speaker_sentence_regex = re.compile(r'([mf])(\\d+)_(\\d+)')\n",
    "def parse_speaker_sentence(value):\n",
    "    match = speaker_sentence_regex.match(value)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "    \n",
    "print(parse_speaker_sentence('m0001_31'))\n",
    "\n",
    "\n",
    "timestamp_format='%Y%m%d%H%M%S%f'\n",
    "def parse_timestamp(timestamp):\n",
    "    return pd.to_datetime(timestamp, format=timestamp_format)\n",
    "\n",
    "print(parse_timestamp('20150129213253016'))\n",
    "\n",
    "\n",
    "def parse_gender(flag):\n",
    "    return flag == 'm'\n",
    "\n",
    "def parse_flag(flag):\n",
    "    return flag == 'Y'\n",
    "\n",
    "\n",
    "def load_trials(*paths):\n",
    "    columns = ([], [], [], [], [], [], [], [], [], [])\n",
    "    \n",
    "    for line in read_files(*paths):\n",
    "        speaker_sentence, recording, tc, tw, ic, iw = line.strip().split(',')\n",
    "        \n",
    "        expected_gender, expected_speaker_id, expected_sentence_id = parse_speaker_sentence(speaker_sentence)\n",
    "        trial_gender, trial_speaker_id, trial_timestamp, trial_sentence_id = parse_recording(recording)\n",
    "        \n",
    "        expected_is_male = parse_gender(expected_gender)\n",
    "        trial_is_male = parse_gender(trial_gender)\n",
    "        \n",
    "        target_person = parse_flag(tc) or parse_flag(tw)\n",
    "        correct_sentence = parse_flag(tc) or parse_flag(ic)\n",
    "        \n",
    "        trial_timestamp = parse_timestamp(trial_timestamp)\n",
    "        pcm_path = recording + '.pcm'\n",
    "        \n",
    "        record = (expected_is_male, expected_speaker_id, expected_sentence_id, \n",
    "                  trial_is_male, trial_speaker_id, trial_timestamp, trial_sentence_id,\n",
    "                  pcm_path, target_person, correct_sentence)\n",
    "        \n",
    "        for value, column in zip(record, columns):\n",
    "            column.append(value)\n",
    "        \n",
    "    data = {'expected_is_male':     pd.Series(columns[0], dtype=np.bool), \n",
    "            'expected_speaker_id':  pd.Series(columns[1], dtype=np.int16), \n",
    "            'expected_sentence_id': pd.Series(columns[2], dtype=np.int16), \n",
    "            'trial_is_male':        pd.Series(columns[3], dtype=np.bool), \n",
    "            'trial_speaker_id':     pd.Series(columns[4], dtype=np.int16), \n",
    "            'trial_timestamp':      pd.Series(columns[5], dtype='datetime64[ns]'), \n",
    "            'trial_sentence_id':    pd.Series(columns[6], dtype=np.int16),\n",
    "            'pcm_path':             pd.Series(columns[7], dtype=str), \n",
    "            'target_person':        pd.Series(columns[8], dtype=np.bool), \n",
    "            'correct_sentence':     pd.Series(columns[9], dtype=np.bool)}\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "        \n",
    "\n",
    "def load_enrollments(*paths):\n",
    "    columns = ([], [], [], [], [])\n",
    "\n",
    "    for line in read_files(*paths):\n",
    "        speaker_sentence, recordings = line.strip().split(' ', 1)\n",
    "        for recording in recordings.split(','):\n",
    "            gender, speaker_id, timestamp, sentence_id = parse_recording(recording)\n",
    "            \n",
    "            is_male = parse_gender(gender)\n",
    "            timestamp = parse_timestamp(timestamp)\n",
    "            pcm_path = recording + '.pcm'\n",
    "            \n",
    "            record = (is_male, speaker_id, timestamp, sentence_id, pcm_path)\n",
    "\n",
    "            for value, column in zip(record, columns):\n",
    "                column.append(value)\n",
    "\n",
    "    data = {'is_male':     pd.Series(columns[0], dtype=np.bool), \n",
    "            'speaker_id':  pd.Series(columns[1], dtype=np.int16), \n",
    "            'timestamp':   pd.Series(columns[2], dtype='datetime64[ns]'), \n",
    "            'sentence_id': pd.Series(columns[3], dtype=np.int16),\n",
    "            'pcm_path':    pd.Series(columns[4], dtype=str)}\n",
    "    return pd.DataFrame.from_dict(data)\n",
    "\n",
    "\n",
    "def load_pcm(root, path):\n",
    "    full_path = os.path.join(root, path)\n",
    "    return np.fromfile(full_path, np.int16)\n",
    "\n",
    "load_pcm = ft.partial(load_pcm, '../input/reddots_r2015q4_v1/pcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_1 = load_trials('../input/reddots_r2015q4_v1/ndx/f_part_01.ndx',\n",
    "                       '../input/reddots_r2015q4_v1/ndx/m_part_01.ndx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments_1 = load_enrollments('../input/reddots_r2015q4_v1/ndx/f_part_01.trn', \n",
    "                                 '../input/reddots_r2015q4_v1/ndx/m_part_01.trn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_sentence                  bool\n",
      "expected_is_male                  bool\n",
      "expected_sentence_id             int16\n",
      "expected_speaker_id              int16\n",
      "pcm_path                        object\n",
      "target_person                     bool\n",
      "trial_is_male                     bool\n",
      "trial_sentence_id                int16\n",
      "trial_speaker_id                 int16\n",
      "trial_timestamp         datetime64[ns]\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct_sentence</th>\n",
       "      <th>expected_is_male</th>\n",
       "      <th>expected_sentence_id</th>\n",
       "      <th>expected_speaker_id</th>\n",
       "      <th>pcm_path</th>\n",
       "      <th>target_person</th>\n",
       "      <th>trial_is_male</th>\n",
       "      <th>trial_sentence_id</th>\n",
       "      <th>trial_speaker_id</th>\n",
       "      <th>trial_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1283856</td>\n",
       "      <td>1283856</td>\n",
       "      <td>1.283856e+06</td>\n",
       "      <td>1.283856e+06</td>\n",
       "      <td>1283856</td>\n",
       "      <td>1283856</td>\n",
       "      <td>1283856</td>\n",
       "      <td>1.283856e+06</td>\n",
       "      <td>1.283856e+06</td>\n",
       "      <td>1283856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4726</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m0020/20150802232439669_m0020_38.pcm</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-12 05:04:47.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1155456</td>\n",
       "      <td>1233280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320</td>\n",
       "      <td>1245096</td>\n",
       "      <td>1233280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-29 10:57:40.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-17 10:02:04.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.549457e+01</td>\n",
       "      <td>2.533627e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.547157e+01</td>\n",
       "      <td>2.298235e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.870385e+00</td>\n",
       "      <td>1.751693e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.862488e+00</td>\n",
       "      <td>1.867127e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.500000e+01</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.500000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>6.700000e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       correct_sentence expected_is_male  expected_sentence_id  \\\n",
       "count           1283856          1283856          1.283856e+06   \n",
       "unique                2                2                   NaN   \n",
       "top               False             True                   NaN   \n",
       "freq            1155456          1233280                   NaN   \n",
       "first               NaN              NaN                   NaN   \n",
       "last                NaN              NaN                   NaN   \n",
       "mean                NaN              NaN          3.549457e+01   \n",
       "std                 NaN              NaN          2.870385e+00   \n",
       "min                 NaN              NaN          3.100000e+01   \n",
       "25%                 NaN              NaN          3.300000e+01   \n",
       "50%                 NaN              NaN          3.500000e+01   \n",
       "75%                 NaN              NaN          3.800000e+01   \n",
       "max                 NaN              NaN          4.000000e+01   \n",
       "\n",
       "        expected_speaker_id                              pcm_path  \\\n",
       "count          1.283856e+06                               1283856   \n",
       "unique                  NaN                                  4726   \n",
       "top                     NaN  m0020/20150802232439669_m0020_38.pcm   \n",
       "freq                    NaN                                   320   \n",
       "first                   NaN                                   NaN   \n",
       "last                    NaN                                   NaN   \n",
       "mean           2.533627e+01                                   NaN   \n",
       "std            1.751693e+01                                   NaN   \n",
       "min            1.000000e+00                                   NaN   \n",
       "25%            1.200000e+01                                   NaN   \n",
       "50%            2.100000e+01                                   NaN   \n",
       "75%            4.100000e+01                                   NaN   \n",
       "max            6.000000e+01                                   NaN   \n",
       "\n",
       "       target_person trial_is_male  trial_sentence_id  trial_speaker_id  \\\n",
       "count        1283856       1283856       1.283856e+06      1.283856e+06   \n",
       "unique             2             2                NaN               NaN   \n",
       "top            False          True                NaN               NaN   \n",
       "freq         1245096       1233280                NaN               NaN   \n",
       "first            NaN           NaN                NaN               NaN   \n",
       "last             NaN           NaN                NaN               NaN   \n",
       "mean             NaN           NaN       3.547157e+01      2.298235e+01   \n",
       "std              NaN           NaN       2.862488e+00      1.867127e+01   \n",
       "min              NaN           NaN       3.100000e+01      1.000000e+00   \n",
       "25%              NaN           NaN       3.300000e+01      8.000000e+00   \n",
       "50%              NaN           NaN       3.500000e+01      1.800000e+01   \n",
       "75%              NaN           NaN       3.800000e+01      4.000000e+01   \n",
       "max              NaN           NaN       4.000000e+01      6.700000e+01   \n",
       "\n",
       "                   trial_timestamp  \n",
       "count                      1283856  \n",
       "unique                        4726  \n",
       "top     2015-06-12 05:04:47.622000  \n",
       "freq                           320  \n",
       "first   2015-01-29 10:57:40.589000  \n",
       "last    2015-08-17 10:02:04.104000  \n",
       "mean                           NaN  \n",
       "std                            NaN  \n",
       "min                            NaN  \n",
       "25%                            NaN  \n",
       "50%                            NaN  \n",
       "75%                            NaN  \n",
       "max                            NaN  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trials_1.dtypes)\n",
    "trials_1.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_male                  bool\n",
      "pcm_path               object\n",
      "sentence_id             int16\n",
      "speaker_id              int16\n",
      "timestamp      datetime64[ns]\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_male</th>\n",
       "      <th>pcm_path</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1134</td>\n",
       "      <td>1134</td>\n",
       "      <td>1134.000000</td>\n",
       "      <td>1134.000000</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>1134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>True</td>\n",
       "      <td>m0017/20150218225158037_m0017_37.pcm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-03-25 22:32:45.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>960</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-29 10:56:01.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-25 17:57:29.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.478836</td>\n",
       "      <td>23.052910</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.866089</td>\n",
       "      <td>17.624424</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_male                              pcm_path  sentence_id  \\\n",
       "count     1134                                  1134  1134.000000   \n",
       "unique       2                                  1134          NaN   \n",
       "top       True  m0017/20150218225158037_m0017_37.pcm          NaN   \n",
       "freq       960                                     1          NaN   \n",
       "first      NaN                                   NaN          NaN   \n",
       "last       NaN                                   NaN          NaN   \n",
       "mean       NaN                                   NaN    35.478836   \n",
       "std        NaN                                   NaN     2.866089   \n",
       "min        NaN                                   NaN    31.000000   \n",
       "25%        NaN                                   NaN    33.000000   \n",
       "50%        NaN                                   NaN    35.000000   \n",
       "75%        NaN                                   NaN    38.000000   \n",
       "max        NaN                                   NaN    40.000000   \n",
       "\n",
       "         speaker_id                   timestamp  \n",
       "count   1134.000000                        1134  \n",
       "unique          NaN                        1134  \n",
       "top             NaN  2015-03-25 22:32:45.259000  \n",
       "freq            NaN                           1  \n",
       "first           NaN  2015-01-29 10:56:01.404000  \n",
       "last            NaN  2015-06-25 17:57:29.928000  \n",
       "mean      23.052910                         NaN  \n",
       "std       17.624424                         NaN  \n",
       "min        1.000000                         NaN  \n",
       "25%        7.000000                         NaN  \n",
       "50%       19.000000                         NaN  \n",
       "75%       38.000000                         NaN  \n",
       "max       60.000000                         NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(enrollments_1.dtypes)\n",
    "enrollments_1.describe(include='all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
